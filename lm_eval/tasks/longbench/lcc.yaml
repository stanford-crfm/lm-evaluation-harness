
tag:
  - longbench
task: longbench_lcc
dataset_path: THUDM/LongBench
test_split: test
dataset_name: lcc
<<<<<<< HEAD
doc_to_text: 'Please complete the code given below. \n{{context}}Next line of code:\n'
=======
doc_to_text: "Please complete the code given below. \n{{context}}Next line of code:\n"
>>>>>>> de496b80d60c267a2d7eea3b3c1dc40f693daee7
doc_to_target: '{{answers}}'
process_results: !function metrics.get_code_sim_score
generation_kwargs:
  max_gen_toks: 64
  temperature: 1
<<<<<<< HEAD
  do_sample: True
=======
  do_sample: False
>>>>>>> de496b80d60c267a2d7eea3b3c1dc40f693daee7
  until: []
metric_list:
  - metric: "code_sim_score"
    aggregation: mean
    higher_is_better: True
metadata:
<<<<<<< HEAD
  version: 3.0
=======
  version: 4.0
>>>>>>> de496b80d60c267a2d7eea3b3c1dc40f693daee7
