
tag:
  - longbench
task: longbench_qmsum
dataset_path: THUDM/LongBench
test_split: test
dataset_name: qmsum
<<<<<<< HEAD
doc_to_text: 'You are given a meeting transcript and a query containing a question or instruction. Answer the query in one or more sentences.\n\nTranscript:\n{{context}}\n\nNow, answer the query based on the above meeting transcript in one or more sentences.\n\nQuery: {{input}}\nAnswer:'
=======
doc_to_text: "You are given a meeting transcript and a query containing a question or instruction. Answer the query in one or more sentences.\n\nTranscript:\n{{context}}\n\nNow, answer the query based on the above meeting transcript in one or more sentences.\n\nQuery: {{input}}\nAnswer:"
>>>>>>> de496b80d60c267a2d7eea3b3c1dc40f693daee7
doc_to_target: '{{answers}}'
process_results: !function metrics.get_rouge_score
generation_kwargs:
  max_gen_toks: 512
  temperature: 1
<<<<<<< HEAD
  do_sample: True
=======
  do_sample: False
>>>>>>> de496b80d60c267a2d7eea3b3c1dc40f693daee7
  until: []
metric_list:
  - metric: "rouge_score"
    aggregation: mean
    higher_is_better: True
metadata:
<<<<<<< HEAD
  version: 3.0
=======
  version: 4.0
>>>>>>> de496b80d60c267a2d7eea3b3c1dc40f693daee7
